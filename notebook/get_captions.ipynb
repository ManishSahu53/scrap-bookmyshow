{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import dtype\n",
    "\n",
    "import transformers\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "from src.general_utils import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flash_attn einops timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "\n",
    "def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "    if not str(filename).endswith(\"modeling_florence2.py\"):\n",
    "        return get_imports(filename)\n",
    "    imports = get_imports(filename)\n",
    "    imports.remove(\"flash_attn\")\n",
    "    return imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/Florence-2-large'\n",
    "path_cache_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/experiment/pretrained_model/florence-2'\n",
    "\n",
    "with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports): #workaround for unnecessary flash_attn requirement\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation=\"sdpa\", trust_remote_code=True, cache_dir=path_cache_dir)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, cache_dir=path_cache_dir)\n",
    "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def florence2(image, task_prompt, text_input=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calling the Microsoft Florence2 model\n",
    "    \"\"\"\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        # print(inputs[\"input_ids\"].shape, inputs[\"pixel_values\"].shape, inputs[\"attention_mask\"].shape, inputs)\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(),\n",
    "            pixel_values=inputs[\"pixel_values\"].cuda(),\n",
    "            max_new_tokens=1024,\n",
    "            early_stopping=False,\n",
    "            do_sample=False,\n",
    "            num_beams=3,\n",
    "        )\n",
    "    else:\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            max_new_tokens=1024,\n",
    "            early_stopping=False,\n",
    "            do_sample=False,\n",
    "            num_beams=3,\n",
    "        )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids,\n",
    "                                            skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height))\n",
    "\n",
    "    return parsed_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_tags = [\n",
    "    '<MORE_DETAILED_CAPTION>',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/data/wickedweasel'\n",
    "path_image_list = util.list_list(path_image_dir, ('jpg', 'jpeg', 'png'))\n",
    "n = len(path_image_list)\n",
    "print(f'Numnber of images: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_caption_list = []\n",
    "task_prompt = '<MORE_DETAILED_CAPTION>'\n",
    "\n",
    "for path_image in tqdm(path_image_list):\n",
    "    basename = util.get_file_name(path_image)\n",
    "\n",
    "    image = Image.open(path_image).convert('RGB')\n",
    "    width, height = image.size\n",
    "\n",
    "    desired_height = 1024\n",
    "    desired_width = int(width * desired_height / height)\n",
    "    image_small = image.resize((desired_width, desired_height))\n",
    "    \n",
    "    parsed_answer = florence2(image, task_prompt, text_input=None, device='cpu')\n",
    "    temp_caption_dict = {\n",
    "        'title': basename,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"path_image\": path_image,\n",
    "        'more_detail_caption': parsed_answer[task_prompt].replace('\\n', ''),\n",
    "    }\n",
    "\n",
    "    data_caption_list.append(temp_caption_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = f'/workspace/jupyter_notebooks/manish_sahu/clipeus/training/mystique/mystique-visuals/data/assets/captions/{type_name}/caption.csv'\n",
    "data_csv = pd.DataFrame(data_caption_list)\n",
    "data_csv.to_csv(path_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numnber of images: 9241\n"
     ]
    }
   ],
   "source": [
    "path_image_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/data/wickedweasel/images'\n",
    "path_image_list = util.list_list(path_image_dir, ('jpg', 'jpeg', 'png'))\n",
    "n = len(path_image_list)\n",
    "print(f'Numnber of images: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9241/9241 [00:00<00:00, 620321.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_image</th>\n",
       "      <th>clothes_class</th>\n",
       "      <th>clothes_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/manish.sahu/Downloads/tiler/scrap-bookm...</td>\n",
       "      <td>activewear</td>\n",
       "      <td>swimwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/manish.sahu/Downloads/tiler/scrap-bookm...</td>\n",
       "      <td>activewear</td>\n",
       "      <td>swimwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          path_image clothes_class  \\\n",
       "0  /Users/manish.sahu/Downloads/tiler/scrap-bookm...    activewear   \n",
       "1  /Users/manish.sahu/Downloads/tiler/scrap-bookm...    activewear   \n",
       "\n",
       "  clothes_type  \n",
       "0     swimwear  \n",
       "1     swimwear  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "data_df = []\n",
    "\n",
    "for path_image in tqdm(path_image_list):\n",
    "    clothes_type_1 = path_image.split('/')[-4]\n",
    "    clothes_type_2 = path_image.split('/')[-3]\n",
    "    # print(f'Clothes type 1: {clothes_type_1}')\n",
    "    # print(f'Clothes type 2: {clothes_type_2}')\n",
    "\n",
    "    data_df.append({\n",
    "        'path_image': path_image,\n",
    "        'clothes_class': clothes_type_1,\n",
    "        'clothes_type': clothes_type_2,\n",
    "    })\n",
    "\n",
    "data_df = pd.DataFrame(data_df)\n",
    "data_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 15\n",
    "clothes_class_list = data_df['clothes_class'].unique()\n",
    "clothes_type_list = data_df['clothes_type'].unique()\n",
    "sample_df = []\n",
    "\n",
    "for clothes_class in clothes_class_list:\n",
    "    for clothes_type in clothes_type_list:\n",
    "        temp_df = data_df[(data_df['clothes_class'] == clothes_class) & (data_df['clothes_type'] == clothes_type)]\n",
    "        n = len(temp_df)\n",
    "        temp_sample = min(n, sample)\n",
    "\n",
    "        sample_df.append(temp_df.sample(temp_sample))\n",
    "        # print(f'Clothes class: {clothes_class}, Clothes type: {clothes_type}, Numnber of images: {n}')\n",
    "    \n",
    "sample_df = pd.concat(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:00<00:00, 1525.18it/s]\n"
     ]
    }
   ],
   "source": [
    "path_output_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/data/wickedweasel/sample_images'\n",
    "util.check_dir(path_output_dir)\n",
    "\n",
    "path_image_list = sample_df['path_image'].tolist()\n",
    "class_list = sample_df['clothes_class'].tolist()\n",
    "type_list = sample_df['clothes_type'].tolist()\n",
    "n = len(path_image_list)\n",
    "\n",
    "for index in tqdm(range(n)):\n",
    "    path_image = path_image_list[index]\n",
    "    class_name = class_list[index]\n",
    "    type_name = type_list[index]\n",
    "\n",
    "    basename = util.getNamenoExt(path_image)\n",
    "    \n",
    "    path_output = os.path.join(path_output_dir, f'{class_name}-{type_name}-{basename}.jpg')\n",
    "    shutil.copy(path_image, path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mystique-visual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
