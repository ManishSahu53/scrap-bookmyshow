{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.general_utils import util\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numnber of images: 9241\n"
     ]
    }
   ],
   "source": [
    "path_image_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/data/wickedweasel'\n",
    "path_image_list = util.list_list(path_image_dir, ('jpg', 'jpeg', 'png'))\n",
    "n = len(path_image_list)\n",
    "print(f'Numnber of images: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "url = \"https://www.wickedweasel.com/en-us/outerwear/skirts\"\n",
    "base_product_url = 'https://www.wickedweasel.com'\n",
    "path_output_dir = '/Users/manish.sahu/Downloads/tiler/scrap-bookmyshow/data/wickedweasel/images/shorts'\n",
    "util.check_dir(path_output_dir)\n",
    "\n",
    "# Send a GET request to the website\n",
    "def parse_url(url:str):\n",
    "    driver = webdriver.Firefox()\n",
    "    try:\n",
    "        # Set the page load timeout\n",
    "        driver.set_page_load_timeout(10)\n",
    "\n",
    "        # Open the URL\n",
    "        print(f\"Loading page: {url}\")\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(f\"Page load exceeded {10} seconds. Continuing with scraping...\")\n",
    "\n",
    "\n",
    "    # Try to close the popup if it appears\n",
    "    try:\n",
    "        # Locate the close button for the popup and click it\n",
    "        popup_close_button = driver.find_element(By.CSS_SELECTOR, 'button.mfp-close')\n",
    "        popup_close_button.click()\n",
    "        time.sleep(2)  # Wait a moment for the popup to close\n",
    "    except Exception as e:\n",
    "        print(\"Popup not found or unable to close it:\", e)\n",
    "\n",
    "        \n",
    "    # response = requests.get(url)\n",
    "    # soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page: https://www.wickedweasel.com/en-us/outerwear/skirts\n",
      "Page load exceeded 10 seconds. Continuing with scraping...\n"
     ]
    }
   ],
   "source": [
    "soup = parse_url(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [02:49<00:00, 14.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Find all the dress containers (adjust selectors based on the website's structure)\n",
    "dress_containers = soup.find_all('div', class_='product-tile-container')\n",
    "\n",
    "# Extract details for each dress\n",
    "for dress in tqdm(dress_containers):\n",
    "    try:\n",
    "        product_name = dress.text.strip().replace(' ', '-')\n",
    "        \n",
    "        if product_name == 'promo':\n",
    "            continue\n",
    "\n",
    "        product_url = base_product_url + dress.find(class_='product-item')['href']\n",
    "        path_image_dir = os.path.join(path_output_dir, product_name)\n",
    "        util.check_dir(path_image_dir)\n",
    "\n",
    "        product_soup = parse_url(url=product_url)\n",
    "        \n",
    "        image_list = product_soup.find_all(class_='carousel-container')[0].find_all('li')\n",
    "        number_of_images = len(image_list)\n",
    "        \n",
    "        for i in range(number_of_images):\n",
    "            image_url = image_list[i].find('img')['src']\n",
    "            basename = os.path.basename(image_url).split('?')[0]\n",
    "            path_image = os.path.join(path_image_dir, f'{basename}')\n",
    "\n",
    "            if not os.path.exists(path_image):\n",
    "                response = requests.get(image_url)\n",
    "                with open(path_image, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                # print(f\"Downloaded: {path_image}\")\n",
    "            else:\n",
    "                # print(f\"Already exists: {path_image}\")\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break\n",
    "    \n",
    "    # # title = dress.find('div', class_='product-name').text.strip()\n",
    "    # # price = dress.find('span', class_='price').text.strip()\n",
    "    # # link = dress.find('a', class_='product-link')['href']\n",
    "    \n",
    "    # print(f\"Title: {title}\")\n",
    "    # print(f\"Price: {price}\")\n",
    "    # print(f\"Link: {link}\")\n",
    "    # print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.wickedweasel.com/en-us/bikinis/tri-top-bikini'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bikinis'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mystique-visual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
